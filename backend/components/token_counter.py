# -*- coding: utf-8 -*-
"""
@author: FinAI-Chat
@file: token_counter.py
@time: 2025-11-06
@desc: å…¨å±€ Token è®¡æ•°å™¨ï¼Œç”¨äºè·Ÿè¸ªæ‰€æœ‰ LLM è°ƒç”¨çš„ token æ¶ˆè€—
"""
import tiktoken
import logging
from typing import Dict, Any
from threading import Lock


class TokenCounter:
    """å…¨å±€ Token è®¡æ•°å™¨ï¼Œçº¿ç¨‹å®‰å…¨"""
    
    def __init__(self):
        self._lock = Lock()
        self.stats = {
            # æŒ‰æ¨¡å‹ç±»å‹åˆ†ç±»
            "fast_llm": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0, "calls": 0},
            "smart_llm": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0, "calls": 0},
            "writer_llm": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0, "calls": 0},
            "search_llm": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0, "calls": 0},
            # æ€»è®¡
            "total": {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0, "calls": 0}
        }
        
        # ä½¿ç”¨ cl100k_base ç¼–ç å™¨ï¼ˆé€‚ç”¨äº GPT-3.5/4 å’Œ Geminiï¼‰
        try:
            self.encoder = tiktoken.get_encoding("cl100k_base")
        except Exception as e:
            logging.warning(f"æ— æ³•åŠ è½½ tiktoken ç¼–ç å™¨: {e}ï¼Œå°†ä½¿ç”¨ç®€å•ä¼°ç®—")
            self.encoder = None
    
    def count_tokens(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡"""
        if not text:
            return 0
        
        if self.encoder:
            try:
                return len(self.encoder.encode(text))
            except Exception as e:
                logging.warning(f"Token è®¡æ•°å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•ä¼°ç®—")
        
        # ç®€å•ä¼°ç®—ï¼šä¸­æ–‡çº¦1.5å­—ç¬¦/tokenï¼Œè‹±æ–‡çº¦4å­—ç¬¦/token
        # æ··åˆæ–‡æœ¬å¹³å‡çº¦2.5å­—ç¬¦/token
        return int(len(text) / 2.5)
    
    def add_call(self, llm_type: str, prompt: str, response: str):
        """
        è®°å½•ä¸€æ¬¡ LLM è°ƒç”¨
        
        Args:
            llm_type: LLM ç±»å‹ï¼ˆfast_llm, smart_llm, writer_llm, search_llmï¼‰
            prompt: è¾“å…¥çš„ prompt
            response: LLM çš„å“åº”
        """
        prompt_tokens = self.count_tokens(prompt)
        completion_tokens = self.count_tokens(response)
        total_tokens = prompt_tokens + completion_tokens
        
        with self._lock:
            if llm_type not in self.stats:
                logging.warning(f"æœªçŸ¥çš„ LLM ç±»å‹: {llm_type}ï¼Œå°†è®°å½•åˆ° total")
                llm_type = "total"
            
            # æ›´æ–°å¯¹åº”ç±»å‹çš„ç»Ÿè®¡
            self.stats[llm_type]["prompt_tokens"] += prompt_tokens
            self.stats[llm_type]["completion_tokens"] += completion_tokens
            self.stats[llm_type]["total_tokens"] += total_tokens
            self.stats[llm_type]["calls"] += 1
            
            # æ›´æ–°æ€»è®¡
            self.stats["total"]["prompt_tokens"] += prompt_tokens
            self.stats["total"]["completion_tokens"] += completion_tokens
            self.stats["total"]["total_tokens"] += total_tokens
            self.stats["total"]["calls"] += 1
            
            logging.debug(
                f"Tokenè®¡æ•°: {llm_type} - "
                f"è¾“å…¥:{prompt_tokens}, è¾“å‡º:{completion_tokens}, æ€»è®¡:{total_tokens}"
            )
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–å½“å‰ç»Ÿè®¡æ•°æ®"""
        with self._lock:
            return dict(self.stats)
    
    def get_summary(self) -> str:
        """è·å–æ ¼å¼åŒ–çš„ç»Ÿè®¡æ‘˜è¦"""
        stats = self.get_stats()
        
        lines = []
        lines.append("=" * 80)
        lines.append("ğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡")
        lines.append("=" * 80)
        
        for llm_type, data in stats.items():
            if llm_type == "total":
                lines.append("-" * 80)
            
            if data["calls"] > 0:
                type_name = {
                    "fast_llm": "Fast LLM (gemini-2.0-flash)",
                    "smart_llm": "Smart LLM (gemini-2.5-flash)",
                    "writer_llm": "Writer LLM (gemini-2.5-pro)",
                    "search_llm": "Search LLM (gemini-2.0-flash)",
                    "total": "æ€»è®¡"
                }.get(llm_type, llm_type)
                
                lines.append(f"{type_name}:")
                lines.append(f"  è°ƒç”¨æ¬¡æ•°: {data['calls']:,} æ¬¡")
                lines.append(f"  è¾“å…¥ Tokens: {data['prompt_tokens']:,}")
                lines.append(f"  è¾“å‡º Tokens: {data['completion_tokens']:,}")
                lines.append(f"  æ€»è®¡ Tokens: {data['total_tokens']:,}")
                lines.append("")
        
        lines.append("=" * 80)
        
        return "\n".join(lines)
    
    def reset(self):
        """é‡ç½®æ‰€æœ‰ç»Ÿè®¡æ•°æ®"""
        with self._lock:
            for key in self.stats:
                self.stats[key] = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0, "calls": 0}


# å…¨å±€å•ä¾‹å®ä¾‹
_global_token_counter = TokenCounter()


def get_token_counter() -> TokenCounter:
    """è·å–å…¨å±€ token è®¡æ•°å™¨å®ä¾‹"""
    return _global_token_counter

