# -*- coding: utf-8 -*-
"""
@author: FinAI-Chat
@file: main.py
@time: 2024-07-30 11:00
@desc: DeepReader Agent çš„ä¸»ç¨‹åºå…¥å£
"""
import asyncio
import os
import sys
import json
import logging
import hashlib
from pathlib import Path
from datetime import datetime
from pprint import pprint
from typing import Dict, Any, List, Optional

# --- 1. åˆå§‹åŒ–ç¯å¢ƒ ---
def setup_environment():
    """è®¾ç½®å·¥ä½œç›®å½•å’Œ sys.pathï¼Œç¡®ä¿è„šæœ¬ä» dynamic-gptr æ ¹ç›®å½•è¿è¡Œ"""
    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç›®å½•
    script_dir = Path(__file__).parent.resolve()
    # å¯»æ‰¾ dynamic-gptr æ ¹ç›®å½•
    workspace_root = script_dir
    while workspace_root.name != 'dynamic-gptr' and workspace_root.parent != workspace_root:
        workspace_root = workspace_root.parent
    
    if workspace_root.name == 'dynamic-gptr':
        os.chdir(workspace_root)
        print(f"å·¥ä½œç›®å½•å·²åˆ‡æ¢åˆ°: {os.getcwd()}")
    else:
        print("é”™è¯¯: æœªèƒ½åœ¨çˆ¶ç›®å½•ä¸­æ‰¾åˆ° 'dynamic-gptr'ã€‚è¯·ç¡®ä¿é¡¹ç›®ç»“æ„æ­£ç¡®ã€‚")
        sys.exit(1)

    # å°†å·¥ä½œç›®å½•æ·»åŠ åˆ° sys.path
    if str(workspace_root) not in sys.path:
        sys.path.insert(0, str(workspace_root))

setup_environment()

# --- 2. å¯¼å…¥å¿…è¦çš„æ¨¡å— ---
from gpt_researcher.deepreader.backend.read_graph import create_deepreader_graph
from gpt_researcher.deepreader.backend.read_state import DeepReaderState
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver

# --- 3. å®šä¹‰å¸¸é‡ ---
BASE_OUTPUT_DIR = Path("gpt_researcher/deepreader/output")
CACHE_DIR = Path("gpt_researcher/deepreader/backend/cache")
SESSION_CACHE_FILE = CACHE_DIR / "session_cache.json"
CHECKPOINTER_DB_PATH = CACHE_DIR / "checkpoints.sqlite"

# --- 4. é…ç½®æ—¥å¿— ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# è¿‡æ»¤æ‰ä¸€äº›è¿‡äºå†—é•¿çš„ç¬¬ä¸‰æ–¹åº“æ—¥å¿—
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

# --- 5. ä¼šè¯ç®¡ç† ---
def load_session_cache() -> Dict[str, str]:
    """åŠ è½½ä¸Šä¸€æ¬¡çš„ç”¨æˆ·è¾“å…¥"""
    if SESSION_CACHE_FILE.exists():
        try:
            with open(SESSION_CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    return {}

def save_session_cache(data: Dict[str, str]):
    """ä¿å­˜å½“å‰ç”¨æˆ·è¾“å…¥"""
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    with open(SESSION_CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def get_user_inputs(defaults: Dict[str, str]) -> Dict[str, str]:
    """æç¤ºç”¨æˆ·è¾“å…¥å¹¶è·å–å¿…è¦çš„å‚æ•°"""
    print("\\n--- è¯·è¾“å…¥ç ”ç©¶ä»»åŠ¡æ‰€éœ€ä¿¡æ¯ ---")
    
    document_path = input(f"è¯·è¾“å…¥å¾…å¤„ç†æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ [{defaults.get('document_path', '')}]: ") or defaults.get('document_path', '')
    while not Path(document_path).exists() or not Path(document_path).is_file():
        print("âŒ æ–‡ä»¶è·¯å¾„æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
        document_path = input("è¯·è¾“å…¥å¾…å¤„ç†æ–‡ä»¶çš„ç»å¯¹è·¯å¾„: ")

    user_core_question = input(f"è¯·è¾“å…¥æ‚¨çš„æ ¸å¿ƒæ¢ç´¢é—®é¢˜ [{defaults.get('user_core_question', '')}]: ") or defaults.get('user_core_question', '')
    research_role = input(f"è¯·è¾“å…¥æ‚¨æœŸæœ›çš„ç ”ç©¶è§’è‰² [{defaults.get('research_role', 'èµ„æ·±è¡Œä¸šåˆ†æå¸ˆ')}]: ") or defaults.get('research_role', 'èµ„æ·±è¡Œä¸šåˆ†æå¸ˆ')

    return {
        "document_path": document_path,
        "user_core_question": user_core_question,
        "research_role": research_role
    }

# --- 6. ç»“æœæ ¼å¼åŒ–ä¸ä¿å­˜ ---
def _format_summaries_to_md(summaries: Dict[str, str]) -> str:
    """æ ¼å¼åŒ–ç« èŠ‚æ‘˜è¦ä¸º Markdown"""
    if not summaries:
        return "æ²¡æœ‰å¯ç”¨çš„ç« èŠ‚æ‘˜è¦ã€‚"
    content = ["# ç« èŠ‚æ‘˜è¦"]
    # æŒ‰ç« èŠ‚æ ‡é¢˜ï¼ˆé”®ï¼‰æ’åº
    for title, summary in sorted(summaries.items()):
        content.append(f"## {title}\n\n{summary}")
    return "\n\n".join(content)

def _format_thematic_analysis_to_md(analysis: Dict[str, str]) -> str:
    """æ ¼å¼åŒ–ä¸»é¢˜åˆ†æä¸º Markdown"""
    if not analysis:
        return "æ²¡æœ‰å¯ç”¨çš„ä¸»é¢˜åˆ†æã€‚"
    content = ["# ä¸»é¢˜æ€æƒ³åˆ†æ"]
    for key, value in analysis.items():
        formatted_key = key.replace('_', ' ').title()
        content.append(f"## {formatted_key}\n\n{value}")
    return "\n\n".join(content)

def _format_debate_to_md(rounds: List[List[Dict[str, Any]]]) -> str:
    """æ ¼å¼åŒ–æ‰¹åˆ¤æ€§è¾©è®ºä¸º Markdown"""
    if not rounds:
        return "æ²¡æœ‰å¯ç”¨çš„è¾©è®ºè®°å½•ã€‚"
    content = ["# æ‰¹åˆ¤æ€§è¾©è®ºé—®ç­”"]
    for i, round_data in enumerate(rounds):
        content.append(f"## è¾©è®ºè½®æ¬¡ {i+1}")
        if isinstance(round_data, list):
            for item in round_data:
                question = item.get('question', 'N/A')
                answer = item.get('content_retrieve_answer', 'æ— å›ç­”')
                content.append(f"### é—®é¢˜: {question}\n\n**å›ç­”:** {answer}")
    return "\n\n".join(content)

def _format_draft_report_to_md(report_data: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ–æœ€ç»ˆæŠ¥å‘Šä¸º Markdown"""
    if not report_data:
        return "æœªèƒ½ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚"
    
    md_parts = []

    def _parse_recursive(section_list: List[Dict[str, Any]], level: int):
        for section in section_list:
            title = section.get("title", "æ— æ ‡é¢˜")
            md_parts.append(f"{'#' * level} {title}")

            content_brief = section.get("content_brief")
            if content_brief:
                md_parts.append(f"_{content_brief}_")
            
            written_content = section.get("written_content")
            if written_content and isinstance(written_content, list):
                md_parts.append("\n\n".join(written_content))
            
            children = section.get("children")
            if children:
                _parse_recursive(children, level + 1)

    _parse_recursive(report_data, 1)

    return "\n\n".join(md_parts)


def save_results(output_dir: Path, final_state: Dict[str, Any]):
    """å°†æœ€ç»ˆçŠ¶æ€å’Œæ ¼å¼åŒ–åçš„æŠ¥å‘Šä¿å­˜åˆ°æ–‡ä»¶"""
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"\n--- æ­£åœ¨ä¿å­˜ç»“æœè‡³: {output_dir} ---")

    # 1. ä¿å­˜å®Œæ•´çš„æœ€ç»ˆçŠ¶æ€
    final_state_path = output_dir / "final_state.json"
    try:
        # TypedDict è½¬ dict
        serializable_state = dict(final_state)
        with open(final_state_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_state, f, ensure_ascii=False, indent=4)
        print(f"âœ… å®Œæ•´çŠ¶æ€å·²ä¿å­˜: {final_state_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜å®Œæ•´çŠ¶æ€å¤±è´¥: {e}")
        print("--- æœ€ç»ˆçŠ¶æ€å†…å®¹ (pprint): ---")
        pprint(dict(final_state))

    # 2. æ ¼å¼åŒ–å¹¶ä¿å­˜ Markdown æ–‡ä»¶
    report_map = {
        "chapter_summary.md": (_format_summaries_to_md, final_state.get("chapter_summaries")),
        "draft_report.md": (_format_draft_report_to_md, final_state.get("draft_report")),
        "thematic_analysis.md": (_format_thematic_analysis_to_md, final_state.get("thematic_analysis")),
        "debate_questions.md": (_format_debate_to_md, final_state.get("raw_reviewer_outputs"))
    }

    for filename, (formatter, data) in report_map.items():
        output_path = output_dir / filename
        try:
            if data is not None:
                md_content = formatter(data)
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(md_content)
                print(f"âœ… å·²ç”ŸæˆæŠ¥å‘Š: {output_path.name}")
            else:
                print(f"â„¹ï¸ æ— æ•°æ®å¯ç”¨äºç”Ÿæˆ: {output_path.name}")
        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Š {filename} å¤±è´¥: {e}")


# --- 7. ä¸»ç¨‹åº ---
async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    
    # è·å–ç”¨æˆ·è¾“å…¥å¹¶ç»´æŠ¤ä¼šè¯
    session_defaults = load_session_cache()
    user_inputs = get_user_inputs(session_defaults)
    save_session_cache(user_inputs)
    
    document_path = Path(user_inputs["document_path"])
    
    # æå‰è¯»å–æ–‡ä»¶å†…å®¹ï¼Œä»¥ç¡®ä¿åˆå§‹çŠ¶æ€å®Œæ•´
    raw_markdown_content = ""
    try:
        raw_markdown_content = document_path.read_text(encoding='utf-8')
        logging.info(f"âœ… æˆåŠŸé¢„åŠ è½½æ–‡æ¡£: {document_path.name}")
    except Exception as e:
        logging.error(f"âŒ æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶ '{document_path}': {e}")
        return

    # ä¸ºæ¯ä¸ªæ–‡æ¡£åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„çº¿ç¨‹ID
    thread_id = hashlib.md5(str(document_path.resolve()).encode()).hexdigest()
    config = {
        "configurable": {"thread_id": thread_id},
        "recursion_limit": 50000  # æé«˜é€’å½’é™åˆ¶ä»¥å¤„ç†é•¿æ–‡æ¡£
    }

    print(f"\n--- ä»»åŠ¡ä¿¡æ¯ ---")
    print(f"æ–‡æ¡£: {document_path.name}")
    print(f"ä»»åŠ¡ID: {thread_id}")
    
    final_state = None
    # ä½¿ç”¨ async with æ¥æ­£ç¡®ç®¡ç†å¼‚æ­¥ checkpointer çš„ç”Ÿå‘½å‘¨æœŸ
    async with AsyncSqliteSaver.from_conn_string(str(CHECKPOINTER_DB_PATH)) as memory:
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„ä»»åŠ¡
        continue_task = False
        try:
            existing_state = await memory.aget_state(config)
            if existing_state and existing_state.next:
                print("\nâš ï¸ æ£€æµ‹åˆ°è¯¥æ–‡æ¡£æœ‰æœªå®Œæˆçš„ä»»åŠ¡ã€‚")
                choice = input("æ˜¯å¦ä»ä¸Šæ¬¡æ–­ç‚¹å¤„ç»§ç»­? (Y/n): ").lower()
                if choice == 'y' or choice == '':
                    continue_task = True
                    print("â–¶ï¸ æ­£åœ¨æ¢å¤ä»»åŠ¡...")
                else:
                    print("ğŸ—‘ï¸ å·²é€‰æ‹©å¼€å§‹æ–°ä»»åŠ¡ï¼Œæ—§è¿›åº¦å°†è¢«è¦†ç›–ã€‚")
            elif existing_state and not existing_state.next:
                 print("\nâ„¹ï¸ æ£€æµ‹åˆ°è¯¥æ–‡æ¡£å·²æœ‰ä¸€ä¸ªå®Œæˆçš„ä»»åŠ¡ã€‚å°†å¼€å§‹ä¸€ä¸ªæ–°ä»»åŠ¡ã€‚")
        except Exception:
            # å¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œè¡¨ä¸å­˜åœ¨ç­‰
            print("\nâ„¹ï¸ æœªæ£€æµ‹åˆ°å†å²ä»»åŠ¡ï¼Œå°†å¼€å§‹ä¸€ä¸ªæ–°ä»»åŠ¡ã€‚")

        # ç¼–è¯‘å›¾ï¼Œå¹¶ç›´æ¥å…³è” checkpointer
        app = create_deepreader_graph().compile(checkpointer=memory)
        
        if continue_task:
            # åœ¨æ¢å¤å‰ï¼Œå¼ºåˆ¶æ›´æ–°æ£€æŸ¥ç‚¹ä¸­çš„æ–‡æ¡£å†…å®¹ï¼Œç¡®ä¿ä»»åŠ¡çš„å¥å£®æ€§
            try:
                print("â„¹ï¸ ä¸ºç¡®ä¿ä»»åŠ¡èƒ½æ­£ç¡®æ¢å¤ï¼Œæ­£åœ¨æ›´æ–°æ£€æŸ¥ç‚¹ä¸­çš„æ–‡æ¡£å†…å®¹...")
                await memory.aupdate_state(
                    config,
                    {"raw_markdown_content": raw_markdown_content}
                )
                print("âœ… æ£€æŸ¥ç‚¹æ›´æ–°æˆåŠŸã€‚")
            except Exception as e:
                print(f"âš ï¸ æ›´æ–°æ£€æŸ¥ç‚¹å¤±è´¥: {e}ã€‚å°†å°è¯•ç›´æ¥æ¢å¤ï¼Œä½†å¯èƒ½å‡ºé”™ã€‚")
            
            # ä»æ–­ç‚¹æ¢å¤
            async for event in app.astream(None, config=config):
                pprint(event)
                print("-" * 40)
        else:
            # å¼€å§‹ä¸€ä¸ªæ–°ä»»åŠ¡
            initial_state = DeepReaderState(
                user_core_question=user_inputs["user_core_question"],
                research_role=user_inputs["research_role"],
                document_path=str(document_path),
                db_name=str(CACHE_DIR / f"{document_path.stem}_{thread_id}.db"),
                # å…¶ä»–å­—æ®µç”±å›¾å¡«å……
                raw_markdown_content=raw_markdown_content,
                document_metadata={},
                table_of_contents=None,
                reading_snippets=None,
                snippet_analysis_history=[],
                active_memory={},
                chunks=[],
                chapter_summaries={},
                marginalia={},
                entities=[],
                entity_relationships=[],
                synthesis_report="",
                rag_status=None,
                raw_reviewer_outputs=[],
                report_narrative_outline=None,
                thematic_analysis=None,
                critic_consensus_log=[],
                final_keys=None,
                final_report_outline=None,
                draft_report=None,
                error=None
            )
            async for event in app.astream(initial_state, config=config):
                pprint(event)
                print("-" * 40)

        print("\n--- âœ… å›¾æµç¨‹æ‰§è¡Œå®Œæ¯• ---")

        # è·å–æœ€ç»ˆçŠ¶æ€
        try:
            final_snapshot = await app.aget_state(config)
            if final_snapshot:
                final_state = final_snapshot.values
                print("âœ… æˆåŠŸä»æ£€æŸ¥ç‚¹æ¢å¤æœ€ç»ˆçŠ¶æ€ã€‚")
            else:
                print("âŒ æœªèƒ½è·å–æœ€ç»ˆçŠ¶æ€ã€‚")
                # åœ¨ with å—å†…éƒ¨ï¼Œæ‰€ä»¥ä¸èƒ½ç›´æ¥ return
        except Exception as e:
            print(f"âŒ è·å–æœ€ç»ˆçŠ¶æ€æ—¶å‡ºé”™: {e}")

    # åˆ›å»ºè¾“å‡ºç›®å½•å¹¶ä¿å­˜ç»“æœ (åœ¨ with å—ä¹‹å¤–)
    if final_state:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = BASE_OUTPUT_DIR / f"{timestamp}_{document_path.stem}"
        
        save_results(output_dir, final_state)
    else:
        print("æœªè·å–åˆ°æœ€ç»ˆçŠ¶æ€ï¼Œæ— æ³•ä¿å­˜ç»“æœã€‚")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\\nğŸ›‘ ç”¨æˆ·ä¸­æ–­äº†ç¨‹åºã€‚")
        sys.exit(0)
